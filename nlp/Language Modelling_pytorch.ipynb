{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in = open(\"plots_text.pickle\",\"rb\")\n",
    "movie_plots = pickle.load(pickle_in)\n",
    "\n",
    "# count of movie plot summaries\n",
    "len(movie_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"in the summer of 1943, after he is taken off combat operations for medical reasons, american ssgt john patterson , an army air force gunner, is billeted in the london home of the duke of exmoor  in london's grosvenor square. he is befriended by the duke and british paratrooper major david bruce , who has taken leave to contest a parliamentary by-election. on a weekend visit to the duke's estate near exmoor in devon, patterson meets the duke's granddaughter, lady patricia fairfax , a corporal in the women's auxiliary air force, who is david's childhood sweetheart. after a cool beginning based on cultural misunderstandings, they fall in love. david is unaware of what is happening until the final night before the election, when it becomes clear to him during a party on the estate. the next day, the duke learns that his estate has been appropriated by the american army for a base and that david has lost the election. when patterson realizes that pat and david have long expected to marry, he contrives to obtain medical clearance to go back to combat duty. david and pat have an ugly showdown over patterson, only to learn that he has gone back to war. david realizes that pat still loves patterson and arranges for them to reunite. returning from a mission with heavy battle damage, patterson attempts to help his pilot land their b-17 flying fortress at an emergency landing strip at exmoor, but is killed when the bomber stalls as they manoeuvre to avoid crashing in the village. the duke and his family mourn patterson at a memorial service in the village church, while david takes off with his paratroop unit to parachute into france on d-day.\",\n",
       " \"zack  and his new boyfriend benji  are setting off to vacation at an all-male resort in palm springs with their friend lily . in light of the veritable smorgasbord of available men that are sure to be awaiting their arrival, benji has proposed that he and zack open up their relationship, just for the weekend. he's not ready to limit himself sexually and explains that this will be a good way for them to explore together. zack is less than thrilled with the idea, but he's eager to keep benji happy and, after all, he likes sex too. at the same time, zack's ex, casey , is making his way to the same resort with his hag-in-training, penny . knowing that zack will be there with his new boyfriend, casey immediately goes into panic mode, recruiting his new friend, peter , to be his pretend boyfriend for the weekend, proving to zack that he's had no trouble moving on from their relationship. but it isn't long before all plans go awry, and benji starts making eyes at peter, while zack realizes he might not be as over casey as he'd thought. with the gay boys otherwise engaged, lily and penny are soon locked in combat for the attention of luis, the resort's sexy bartender, who also happens to be the sole straight man in sight.\",\n",
       " 'the film develops between the years 1942 and 2009, alternating between the past and the present. in 1942, 10-year-old sarah starzynski  denies to the authorities carrying out the vel\\' d\\'hiv roundup that her little brother michel is at home, and locks him in a hidden closet. she tells him to stay there and wait until she returns. she takes the key with her when she and her parents are transported to the vélodrome d\\'hiver by the paris police and french secret service where they are held in inhuman conditions.{{cite web}} one lady in a window, as all the jewish families get off the transport bus, lauds the action of the french police saying, \"they had it coming to them\", while another french man in a window shouts in reply, \"don\\'t talk nonsense, after them it will be our turn.\" the deportees are transferred to the beaune-la-rolande, the transit deportation detention camp, in squalid conditions and burning heat, in cramped quarters without adequate water or toilet facilities. first the men then the women are deported to auschwitz, and the children have to stay after being forcefully and cruelly separated from their mothers by the paris police. sarah tries to escape with a friend, rachel, after noticing a small hole in the ground underneath a fence. a sympathetic paris police guard, jacques, whom sarah wins over by calling by name, and convincingly begs to let them go so she can save her brother, hesitates but finally agrees, and lifts the barbed wire over the hole to let them out as he smiles sympathetically. after searching for a safe place, exhausted, sarah and rachel, fall asleep in a dog house at a village home where they had originally been rebuffed. in the morning, they are discovered by its owner. realizing who they are, he and his wife decide to help them. rachel is dying, and when they call attention to the sick girl by calling in a doctor, a skeptical german officer asks them if they know anything about a second child and warns them of the dire consequences of hiding jews — and begins a search for the second child, only to be interrupted when the french physician carries out the body of the rachel who has just died. rachel\\'s body is taken away, while jules and genevieve, the elderly couple, hide sarah in the attic. days later they take her back to her family\\'s apartment building in paris. sneaking past the concierge, sarah runs up to her apartment, knocking on the door furiously. a boy, twelve years old, answers. she rushes in to her old room, past the boy, and unlocks the cupboard. horrified by what she finds, she starts screaming hysterically. after the war, sarah continues to live with the old couple on the farm, together with their two grandsons, who treat her like their own granddaughter/sister, until she is 18. in letters, the couple describes sarah\\'s sadness and melancholy. when she turns 18, though, she moves to the united states, hoping to put everything that happened behind her, using the name dufaure, the surname of the elderly couple. she gets married and has a son, william, although she stops corresponding with jules and genevieve soon after being married. when her son is 9, sarah — no longer able to handle what happened to michel, for whose death she blames herself — commits suicide by driving into the path of a truck, although her son had always been under the impression that her death was an accident. in the present, the french husband of journalist julia  inherits the apartment of his grandparents . having previously done an article on the vel\\' d\\'hiv roundup, julia finds her interest piqued when she learns that the apartment came into her husband\\'s family at about the time of the roundup, and she begins to investigate what happened 65 years earlier. her father-in-law, knowing the back story and wanting to protect his elderly mother  from knowing the truth, resents julia\\'s unwelcome prying, but realizes he will have to bring her in on the story to keep control of it, and tells her what he knows. having got much of the story, she goes on an obsessive quest to find any trace of sarah, eventually learning  of her death and finally locating william . she meets with him and asks him for information about his mother, but learns to her surprise that william does not know his mother\\'s history or even that she was a jew, believing only that she had been a french farm girl. listening in amazement to what julia has uncovered, he refuses to believe it, flatly rejecting the story and brusquely dismissing julia. later, everything is confirmed by his dying father, who finally tells him the whole secret story of sarah\\'s background, including what led to his mother\\'s suicide. meanwhile julia has unexpectedly and joyously discovered that she\\'s pregnant, having given up hope of a second child after years of fertility treatments and unsuccessful attempts to conceive, but her husband flatly disagrees that they should have another child at this point in life. he makes it clear that he wants her to have an abortion, saying he is too old even though he cherishes their teenaged daughter, zoe. she hesitates about getting an abortion, and ultimately keeps the child. later, having divorced her husband and moved to new york city, she gives birth to a daughter. it ends with a scene in the present day in which william, having accepted the truth and contacted julia, meets her for lunch and gives her additional information about his mother. in the end scene, julia has brought her toddler daughter along to the meeting, julia uses the name \"lucy\" in talking to her daughter. later, when william asks her a question about her daughter \"lucy\", julia laughs and tells him that \"no, no, lucy is her toy giraffe.\" \"so what did you name your daughter?\" julia looks at him tenderly: \"her name is sarah.\"',\n",
       " 'as people are enjoying drinks in a bar, a man covered in blood - identified onscreen as \"hero\"  - enters through the door and warns them all of impending danger. no one heeds his warning, so he shows the bar patrons the head of a repulsive creature to make them take him seriously. he is soon pulled through a window and decapitated by one of the monsters, amusingly just after it was implied that his chances of survival were very high. after the carnage, a woman - \"heroine\"  - bursts through the door and reveals herself to be the recently deceased man\\'s wife. after a brief sentimental moment between the wife and her late husband, they begin boarding up the windows in the bar. despite their efforts, a young monster bursts through an uncovered window and begins decapitating the people inside the bar. it dismembers one of the women - \"harley mom\"  - and it is initially assumed that she died from massive blood loss. the monster disappears for some time, then is found attempting to sexually penetrate one of the deer heads nailed to the wall. a shotgun blast removes the deer head and monster from the wall. the monster drops into a freezer which is then sealed shut, trapping it inside. following this, the remaining windows are boarded up and the bar patrons are given a moment of peace. trying to call for help, they learn that the only phone in the bar has been hit by a stray shotgun blast and has been rendered useless. after a short breather, one of the women - \"tuffy\"  - suddenly realizes that her son is still upstairs and runs to get him. once she finds her child the group rejoices until the boy is pulled through a window and eaten by one of the monsters, leaving only his sneaker behind. tuffy is now incapacitated by grief, and the monster then vomits a stream of slime at one of the group - \"beer guy\" . as the remaining people regroup downstairs, they realize that the slime has a decomposing effect and that the victim is being slowly overcome by its effects. the group kills the young monster in the freezer and hangs it outside. the monster\\'s parents quickly have sex and produce two offspring in a matter of seconds, all of whom begin to attack the pub with renewed fury. meanwhile, one of the women - \"honey pie\" ([[jenny wade  - begins washing off the blood and has to take off her clothes, much to the amusement of the others. the patrons regroup and enact various attempts to escape or drive off the monsters, all of which lead to more casualties, including the accidental death of the heroine at the hands of another character . driven by rage over the death of her child, tuffy aggressively takes charge of the remaining survivors, which results in the audience seeing her nickname change from \"tuffy\" to \"heroine 2\". \"honey pie\" successfully makes it to a truck, giving the other characters brief cause for hope . after many attacks and ultimately, a fight to the death between the last remaining humans and monsters, only four people survive the ordeal: bozo, hot wheels, tuffy , and honey pie. one person - \"grandma\"  - seems to survive but is seen being attacked by one of the remaining monsters at the end of the film.',\n",
       " 'after a window washer plunges to his death from a barcelona high rise, several people come to investigate, including security consultant dennis randall . he cannot locate a problem, but decides to investigate further when more gruesome deaths take place inside and around the office building. his investigations prove that there is a sinister force behind all the deaths, a supernatural entity, that is not about to stop.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample random summaries\n",
    "random.sample(movie_plots, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text\n",
    "movie_plots = [re.sub(\"[^a-z' ]\", \"\", i) for i in movie_plots]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create sequences of length 5 tokens\n",
    "def create_seq(text, seq_len = 5):\n",
    "    \n",
    "    sequences = []\n",
    "\n",
    "    # if the number of tokens in 'text' is greater than 5\n",
    "    if len(text.split()) > seq_len:\n",
    "      for i in range(seq_len, len(text.split())):\n",
    "        # select sequence of tokens\n",
    "        seq = text.split()[i-seq_len:i+1]\n",
    "        # add to the list\n",
    "        sequences.append(\" \".join(seq))\n",
    "\n",
    "      return sequences\n",
    "\n",
    "    # if the number of tokens in 'text' is less than or equal to 5\n",
    "    else:\n",
    "      return [text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152644"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = [create_seq(i) for i in movie_plots]\n",
    "\n",
    "# merge list-of-lists into a single list\n",
    "seqs = sum(seqs, [])\n",
    "\n",
    "# count of sequences\n",
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inputs and targets (x and y)\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for s in seqs:\n",
    "  x.append(\" \".join(s.split()[:-1]))\n",
    "  y.append(\" \".join(s.split()[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9415, 'redesign')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create integer-to-token mapping\n",
    "int2token = {}\n",
    "cnt = 0\n",
    "\n",
    "for w in set(\" \".join(movie_plots).split()):\n",
    "  int2token[cnt] = w\n",
    "  cnt+= 1\n",
    "\n",
    "# create token-to-integer mapping\n",
    "token2int = {t: i for i, t in int2token.items()}\n",
    "\n",
    "token2int[\"the\"], int2token[14271]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16592"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set vocabulary size\n",
    "vocab_size = len(int2token)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integer_seq(seq):\n",
    "  return [token2int[w] for w in seq.split()]\n",
    "\n",
    "# convert text sequences to integer sequences\n",
    "x_int = [get_integer_seq(i) for i in x]\n",
    "y_int = [get_integer_seq(i) for i in y]\n",
    "\n",
    "# convert lists to numpy arrays\n",
    "x_int = np.array(x_int)\n",
    "y_int = np.array(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr_x, arr_y, batch_size):\n",
    "         \n",
    "    # iterate through the arrays\n",
    "    prv = 0\n",
    "    for n in range(batch_size, arr_x.shape[0], batch_size):\n",
    "      x = arr_x[prv:n,:]\n",
    "      y = arr_y[prv:n,:]\n",
    "      prv = n\n",
    "      yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_hidden=256, n_layers=4, drop_prob=0.3, lr=0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.emb_layer = nn.Embedding(vocab_size, 200)\n",
    "\n",
    "        ## define the LSTM\n",
    "        self.lstm = nn.LSTM(200, n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        ## define a dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        ## define the fully-connected layer\n",
    "        self.fc = nn.Linear(n_hidden, vocab_size)      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "\n",
    "        ## pass input through embedding layer\n",
    "        embedded = self.emb_layer(x)     \n",
    "        \n",
    "        ## Get the outputs and the new hidden state from the lstm\n",
    "        lstm_output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        ## pass through a dropout layer\n",
    "        out = self.dropout(lstm_output)\n",
    "        \n",
    "        #out = out.contiguous().view(-1, self.n_hidden) \n",
    "        out = out.reshape(-1, self.n_hidden) \n",
    "\n",
    "        ## put \"out\" through the fully-connected layer\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        # if GPU is available\n",
    "        if (torch.cuda.is_available()):\n",
    "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        \n",
    "        # if GPU is not available\n",
    "        else:\n",
    "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "net = WordLSTM()\n",
    "\n",
    "# push the model to GPU (avoid it if you are not using the GPU)\n",
    "net.cuda()\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(net, epochs=10, batch_size=32, lr=0.001, clip=1, print_every=32):\n",
    "    \n",
    "    # optimizer\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    # loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # push model to GPU\n",
    "    net.cuda()\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    for e in range(epochs):\n",
    "\n",
    "        # initialize hidden state\n",
    "        h = net.init_hidden(batch_size)\n",
    "        \n",
    "        for x, y in get_batches(x_int, y_int, batch_size):\n",
    "            counter+= 1\n",
    "            \n",
    "            # convert numpy arrays to PyTorch arrays\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            # push tensors to GPU\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # detach hidden states\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = net(inputs, h)\n",
    "            \n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, targets.view(-1))\n",
    "\n",
    "            # back-propagate error\n",
    "            loss.backward()\n",
    "\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "\n",
    "            # update weigths\n",
    "            opt.step()            \n",
    "            \n",
    "            if counter % print_every == 0:\n",
    "            \n",
    "              print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                    \"Step: {}...\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predict next token\n",
    "def predict(net, tkn, h=None):\n",
    "         \n",
    "  # tensor inputs\n",
    "  x = np.array([[token2int[tkn]]])\n",
    "  inputs = torch.from_numpy(x)\n",
    "  \n",
    "  # push to GPU\n",
    "  inputs = inputs.cuda()\n",
    "\n",
    "  # detach hidden state from history\n",
    "  h = tuple([each.data for each in h])\n",
    "\n",
    "  # get the output of the model\n",
    "  out, h = net(inputs, h)\n",
    "\n",
    "  # get the token probabilities\n",
    "  p = F.softmax(out, dim=1).data\n",
    "\n",
    "  p = p.cpu()\n",
    "\n",
    "  p = p.numpy()\n",
    "  p = p.reshape(p.shape[1],)\n",
    "\n",
    "  # get indices of top 3 values\n",
    "  top_n_idx = p.argsort()[-3:][::-1]\n",
    "\n",
    "  # randomly select one of the three indices\n",
    "  sampled_token_index = top_n_idx[random.sample([0,1,2],1)[0]]\n",
    "\n",
    "  # return the encoded value of the predicted char and the hidden state\n",
    "  return int2token[sampled_token_index], h\n",
    "\n",
    "\n",
    "# function to generate text\n",
    "def sample(net, size, prime='it is'):\n",
    "        \n",
    "    # push to GPU\n",
    "    net.cuda()\n",
    "    \n",
    "    net.eval()\n",
    "\n",
    "    # batch size is 1\n",
    "    h = net.init_hidden(1)\n",
    "\n",
    "    toks = prime.split()\n",
    "\n",
    "    # predict next token\n",
    "    for t in prime.split():\n",
    "      token, h = predict(net, t, h)\n",
    "    \n",
    "    toks.append(token)\n",
    "\n",
    "    # predict subsequent tokens\n",
    "    for i in range(size-1):\n",
    "        token, h = predict(net, toks[-1], h)\n",
    "        toks.append(token)\n",
    "\n",
    "    return ' '.join(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(net, 15, prime = \"one of the\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
